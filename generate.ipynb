{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrlaL4HCYkX",
        "outputId": "eb775965-c232-4d93-d4f4-2708a45aa8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting midiSynth\n",
            "  Downloading midiSynth-0.3-py3-none-any.whl.metadata (588 bytes)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from midiSynth) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from midiSynth) (1.14.1)\n",
            "Collecting pretty-midi>=0.2.9 (from midiSynth)\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython>=7.16.1 in /usr/local/lib/python3.11/dist-packages (from midiSynth) (7.34.0)\n",
            "Collecting pyfluidsynth>=1.3.0 (from midiSynth)\n",
            "  Downloading pyfluidsynth-1.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.16.1->midiSynth)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.16.1->midiSynth) (4.9.0)\n",
            "Collecting mido>=1.1.16 (from pretty-midi>=0.2.9->midiSynth)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty-midi>=0.2.9->midiSynth) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.16.1->midiSynth) (0.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty-midi>=0.2.9->midiSynth) (24.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.16.1->midiSynth) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.16.1->midiSynth) (0.2.13)\n",
            "Downloading midiSynth-0.3-py3-none-any.whl (2.7 kB)\n",
            "Downloading pyfluidsynth-1.3.4-py3-none-any.whl (22 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=0c9161cafbec8c66f1dc691e6255e11dd95cee44b9a063988eb6cc766c82588c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: pyfluidsynth, mido, jedi, pretty-midi, midiSynth\n",
            "Successfully installed jedi-0.19.2 midiSynth-0.3 mido-1.3.3 pretty-midi-0.2.10 pyfluidsynth-1.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install midiSynth\n",
        "from midiSynth.synth import MidiSynth\n",
        "midi_synth = MidiSynth()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeNxirYMCjYE",
        "outputId": "1b9d12c7-ce7d-4a75-cebe-ddd7e871353b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/EMOPIA-main/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax-La6wyDZIA",
        "outputId": "b1a105b3-0717-45fb-d921-2dfdb0951865"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 1)) (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 2)) (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 3)) (2.0.2)\n",
            "Collecting miditoolkit (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 4))\n",
            "  Downloading miditoolkit-1.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 5)) (2.2.2)\n",
            "Collecting ipdb (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 1)) (3.6.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.11/dist-packages (from miditoolkit->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 5)) (2025.1)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.11/dist-packages (from ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.19.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 5)) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb->-r /content/drive/MyDrive/EMOPIA-main/requirements.txt (line 6)) (0.2.13)\n",
            "Downloading miditoolkit-1.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: miditoolkit, ipdb\n",
            "Successfully installed ipdb-0.13.13 miditoolkit-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/EMOPIA-main/workspace/transformer')  # Change to your directory path"
      ],
      "metadata": {
        "id": "Z7nZQVwNCwYP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lWxD6BJ8CYkZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user pytorch-fast-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk-LlR_bI0Sw",
        "outputId": "96f2467d-6710-4c93-d73e-dc2521982f4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-fast-transformers\n",
            "  Downloading pytorch-fast-transformers-0.4.0.tar.gz (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch-fast-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch-fast-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch-fast-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch-fast-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch-fast-transformers) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pytorch-fast-transformers\n",
            "  Building wheel for pytorch-fast-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-fast-transformers: filename=pytorch_fast_transformers-0.4.0-cp311-cp311-linux_x86_64.whl size=21343792 sha256=dcf34b9fcea2f397313aae26cf3e1fb7b7404689ba5f6489935f6d9088a07d03\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/0c/7d/39fe4c512d9a96aac3384d1506af78b0955e71e79163e459ec\n",
            "Successfully built pytorch-fast-transformers\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-fast-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-fast-transformers-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/root/.local/lib/python3.11/site-packages\")  # Ensure Python can find the package\n",
        "\n",
        "import fast_transformers\n",
        "print(fast_transformers.__file__)  # This should print the module's location\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5z-dQ0yTNtI",
        "outputId": "5c1f202b-c775-4c27-f01d-bb1913e62903"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.local/lib/python3.11/site-packages/fast_transformers/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-14fLJ1dUsFK",
        "outputId": "6ab91b42-d0e9-460d-f4c0-40ef6f516079"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "S2xRWnM1CYka"
      },
      "outputs": [],
      "source": [
        "from utils import write_midi\n",
        "from models import TransformerModel, network_paras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc95gL9OCYka"
      },
      "source": [
        "## 1. Prepare dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imcl9-9zCYkb",
        "outputId": "fa5979e6-5a19-43f7-ff37-eecf4c986cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17dKUf33ZsDbHC5Z6rkQclge3ppDTVCMP\n",
            "From (redirected): https://drive.google.com/uc?id=17dKUf33ZsDbHC5Z6rkQclge3ppDTVCMP&confirm=t&uuid=45c5226a-5899-4af7-93c8-693619ad61ed\n",
            "To: /content/co-representation.zip\n",
            "100% 16.6M/16.6M [00:00<00:00, 80.7MB/s]\n",
            "Archive:  co-representation.zip\n",
            "  inflating: ../../dataset/co-representation/ailabs_data.npz  \n",
            "  inflating: ../../dataset/co-representation/ailabs_fn2idx_map.json  \n",
            "  inflating: ../../dataset/co-representation/dictionary.pkl  \n",
            "  inflating: ../../dataset/co-representation/emopia_data.npz  \n",
            "  inflating: ../../dataset/co-representation/emopia_fn2idx_map.json  \n",
            "  inflating: ../../dataset/co-representation/emopia_idx.npz  \n",
            "  inflating: ../../dataset/co-representation/README.md  \n"
          ]
        }
      ],
      "source": [
        "!gdown --id 17dKUf33ZsDbHC5Z6rkQclge3ppDTVCMP\n",
        "!unzip co-representation.zip -d ../../dataset/\n",
        "!rm co-representation.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mCpSJzm3CYkb"
      },
      "outputs": [],
      "source": [
        "path_dictionary = '../../dataset/co-representation/dictionary.pkl'\n",
        "assert os.path.exists(path_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Cmor1ZErCYkb"
      },
      "outputs": [],
      "source": [
        "dictionary = pickle.load(open(path_dictionary, 'rb'))\n",
        "event2word, word2event = dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5rNhPOsdCYkb"
      },
      "outputs": [],
      "source": [
        "# config\n",
        "n_class = []   # num of classes for each token\n",
        "for key in event2word.keys():\n",
        "    n_class.append(len(dictionary[0][key]))\n",
        "n_token = len(n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buMxM0KGCYkc"
      },
      "source": [
        "## 2. Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "o_ucWlOdV1xC",
        "outputId": "e9dff96d-d471-4297-d181-38508ce7fdd0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHKZGSBlCYkc",
        "outputId": "653e571f-02d0-4a19-f71b-0d228f8f3ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Error:\n",
            "\n",
            "\t[Errno 2] No such file or directory: 'exp'\n",
            "\n",
            "To report issues, please visit https://github.com/wkentaro/gdown/issues.\n",
            "unzip:  cannot find or open exp/pretrained_transformer.zip, exp/pretrained_transformer.zip.zip or exp/pretrained_transformer.zip.ZIP.\n",
            "rm: cannot remove 'exp/pretrained_transformer.zip': No such file or directory\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'model_weights.pth', 'drive', 'test.mid', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "!gdown --id 19Seq18b2JNzOamEQMG1uarKjj27HJkHu --output exp/pretrained_transformer.zip\n",
        "!unzip exp/pretrained_transformer.zip -d exp/\n",
        "!rm exp/pretrained_transformer.zip\n",
        "os.listdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hygOdIS6CYkc"
      },
      "outputs": [],
      "source": [
        "path_saved_ckpt = '/content/drive/MyDrive/EMOPIA-main/exp/pretrained_transformer/loss_25_params.pt'\n",
        "assert os.path.exists(path_saved_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.load_state_dict(torch.load(path_saved_ckpt, map_location=device), strict=False)\n"
      ],
      "metadata": {
        "id": "Psubrtx1ma6N",
        "outputId": "1adecd2b-0aee-4be5-da55-835219cf65c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "net = TransformerModel(n_class, is_training=False)\n",
        "\n",
        "# Move model to CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "# Load the model weights with strict=False\n",
        "#path_saved_ckpt = \"path/to/your/model_checkpoint.pth\"  # Ensure this path is correct\n",
        "path_saved_ckpt = '/content/drive/MyDrive/EMOPIA-main/exp/pretrained_transformer/loss_25_params.pt'\n",
        "net.load_state_dict(torch.load(path_saved_ckpt, map_location=device), strict=False)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "net.eval()\n"
      ],
      "metadata": {
        "id": "jTJGmFSnnF0i",
        "outputId": "812a007f-c005-4fee-f75b-4005a3e11ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>: [56, 135, 18, 4, 87, 18, 42, 5]\n",
            " [o] using RNN backend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (loss_func): CrossEntropyLoss()\n",
              "  (word_emb_tempo): Embeddings(\n",
              "    (lut): Embedding(56, 128)\n",
              "  )\n",
              "  (word_emb_chord): Embeddings(\n",
              "    (lut): Embedding(135, 256)\n",
              "  )\n",
              "  (word_emb_barbeat): Embeddings(\n",
              "    (lut): Embedding(18, 64)\n",
              "  )\n",
              "  (word_emb_type): Embeddings(\n",
              "    (lut): Embedding(4, 32)\n",
              "  )\n",
              "  (word_emb_pitch): Embeddings(\n",
              "    (lut): Embedding(87, 512)\n",
              "  )\n",
              "  (word_emb_duration): Embeddings(\n",
              "    (lut): Embedding(18, 128)\n",
              "  )\n",
              "  (word_emb_velocity): Embeddings(\n",
              "    (lut): Embedding(42, 128)\n",
              "  )\n",
              "  (word_emb_emotion): Embeddings(\n",
              "    (lut): Embedding(5, 128)\n",
              "  )\n",
              "  (pos_emb): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (in_linear): Linear(in_features=1376, out_features=512, bias=True)\n",
              "  (transformer_encoder): RecurrentTransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x RecurrentTransformerEncoderLayer(\n",
              "        (attention): RecurrentAttentionLayer(\n",
              "          (inner_attention): RecurrentLinearAttention(\n",
              "            (feature_map): ActivationFunctionFeatureMap()\n",
              "          )\n",
              "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (project_concat_type): Linear(in_features=544, out_features=512, bias=True)\n",
              "  (proj_tempo): Linear(in_features=512, out_features=56, bias=True)\n",
              "  (proj_chord): Linear(in_features=512, out_features=135, bias=True)\n",
              "  (proj_barbeat): Linear(in_features=512, out_features=18, bias=True)\n",
              "  (proj_type): Linear(in_features=512, out_features=4, bias=True)\n",
              "  (proj_pitch): Linear(in_features=512, out_features=87, bias=True)\n",
              "  (proj_duration): Linear(in_features=512, out_features=18, bias=True)\n",
              "  (proj_velocity): Linear(in_features=512, out_features=42, bias=True)\n",
              "  (proj_emotion): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQG5vC-rCYkc",
        "outputId": "571f3582-b900-446d-8e22-8a1841d36b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>: [56, 135, 18, 4, 87, 18, 42, 5]\n",
            " [o] using RNN backend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (loss_func): CrossEntropyLoss()\n",
              "  (word_emb_tempo): Embeddings(\n",
              "    (lut): Embedding(56, 128)\n",
              "  )\n",
              "  (word_emb_chord): Embeddings(\n",
              "    (lut): Embedding(135, 256)\n",
              "  )\n",
              "  (word_emb_barbeat): Embeddings(\n",
              "    (lut): Embedding(18, 64)\n",
              "  )\n",
              "  (word_emb_type): Embeddings(\n",
              "    (lut): Embedding(4, 32)\n",
              "  )\n",
              "  (word_emb_pitch): Embeddings(\n",
              "    (lut): Embedding(87, 512)\n",
              "  )\n",
              "  (word_emb_duration): Embeddings(\n",
              "    (lut): Embedding(18, 128)\n",
              "  )\n",
              "  (word_emb_velocity): Embeddings(\n",
              "    (lut): Embedding(42, 128)\n",
              "  )\n",
              "  (word_emb_emotion): Embeddings(\n",
              "    (lut): Embedding(5, 128)\n",
              "  )\n",
              "  (pos_emb): PositionalEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (in_linear): Linear(in_features=1376, out_features=512, bias=True)\n",
              "  (transformer_encoder): RecurrentTransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x RecurrentTransformerEncoderLayer(\n",
              "        (attention): RecurrentAttentionLayer(\n",
              "          (inner_attention): RecurrentLinearAttention(\n",
              "            (feature_map): ActivationFunctionFeatureMap()\n",
              "          )\n",
              "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (project_concat_type): Linear(in_features=544, out_features=512, bias=True)\n",
              "  (proj_tempo): Linear(in_features=512, out_features=56, bias=True)\n",
              "  (proj_chord): Linear(in_features=512, out_features=135, bias=True)\n",
              "  (proj_barbeat): Linear(in_features=512, out_features=18, bias=True)\n",
              "  (proj_type): Linear(in_features=512, out_features=4, bias=True)\n",
              "  (proj_pitch): Linear(in_features=512, out_features=87, bias=True)\n",
              "  (proj_duration): Linear(in_features=512, out_features=18, bias=True)\n",
              "  (proj_velocity): Linear(in_features=512, out_features=42, bias=True)\n",
              "  (proj_emotion): Linear(in_features=512, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "\"\"\"# init model\n",
        "net = TransformerModel(n_class, is_training=False)\n",
        "net.cuda()\n",
        "net.eval()\n",
        "\n",
        "net.load_state_dict(torch.load(path_saved_ckpt))\"\"\"\n",
        "\"\"\"import torch\n",
        "\n",
        "# Initialize model\n",
        "net = TransformerModel(n_class, is_training=False)\n",
        "\n",
        "# Move model to CPU instead of CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "net.eval()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyV9AYEnCYkc"
      },
      "source": [
        "## 3. Start generating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-QTGN1wCYkd"
      },
      "source": [
        "### 3.1 setup parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DEd4kt3rCYkd"
      },
      "outputs": [],
      "source": [
        "emotion_tag = 1  # the target emotion class you want. It should belongs to [1,2,3,4].\n",
        "path_outfile = 'class2' # output midi file name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the path where you want to save the weights\n",
        "model_path = \"/content/model_weights.pth\"\n",
        "\n",
        "# Save the model state dict\n",
        "torch.save(net.state_dict(), model_path)\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download(model_path)\n"
      ],
      "metadata": {
        "id": "JNhsNfWdjJxa",
        "outputId": "c704f2ed-397e-4f71-98b7-a1cdc9d2ea40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd9b2d7f-63a3-41fa-bb19-bf291a302b7e\", \"model_weights.pth\", 197435718)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLqiIAsCYkd",
        "outputId": "42f54070-6a23-4f40-8634-be0d23a83223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------ initiate ------\n",
            "0               | 0               | 0               | Emotion         | 0               | 0               | 0               | 1               | \n",
            "0               | 0               | Bar             | Metrical        | 0               | 0               | 0               | 0               | \n",
            "------ generate ------\n",
            "\n",
            "--------[Done]--------\n",
            "(390, 8)\n"
          ]
        }
      ],
      "source": [
        "#device = torch.device(\"cuda\")\n",
        "res, _ = net.inference_from_scratch(dictionary, emotion_tag, n_token=8, display=False)\n",
        "write_midi(res, path_outfile + '.mid', word2event)\n",
        "\n",
        "#midi_synth.play_midi(path_outfile + '.mid')\n",
        "#midi_synth.midi2audio(path_outfile + '.mid', path_outfile + '.mp3')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}